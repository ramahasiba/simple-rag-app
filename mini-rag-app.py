# -*- coding: utf-8 -*-
"""Rama_Hasiba - Model 3 Section 1:- Homework.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1j2XkpGwhS9i3DQxZ9B18kvBw63mdNtu4

# Comprehensive Homework: Build and Test a Mini RAG System from Scratch ğŸ§ 

> **ğŸ¯ Today's Goal**: Combine the knowledge from the first three lessons (Embeddings, Retrieval, Generation) to build a functional Retrieval-Augmented Generation (RAG) system from scratch. Then, test it with a self-assessment!
"""

!pip install sentence-transformers transformers torch -q

"""## âš™ï¸ Part 1: The Retriever - Finding the Right Knowledge

First, we'll set up our Retriever. Its job is to take a question and find the most relevant piece of text from our knowledge base.

1.  **Load the Embedding Model** (`all-MiniLM-L6-v2`)
2.  **Create our Knowledge Base**
3.  **Encode Everything into Embeddings**
4.  **Calculate Similarity** to find the best match
"""

import torch
from sentence_transformers import SentenceTransformer, util
from transformers import pipeline

print("âœ… Libraries imported successfully!")

# 1. Load our embedding model
retriever_model = SentenceTransformer('all-MiniLM-L6-v2')

# 2. Create a simple knowledge base
knowledge_base = [
    "The capital of France is Paris, a city famous for the Eiffel Tower and the Louvre museum.",
    "The Amazon rainforest is the world's largest tropical rainforest, known for its incredible biodiversity.",
    "Mount Everest is the highest mountain on Earth, located in the Himalayas.",
    "The Great Wall of China is a series of fortifications stretching over 13,000 miles.",
    "Photosynthesis is the process used by plants to convert light energy into chemical energy."
]

# 3. Encode our knowledge base into embeddings
knowledge_embeddings = retriever_model.encode(knowledge_base, convert_to_tensor=True)

print(f"âœ… Retriever model loaded and knowledge base encoded with {len(knowledge_base)} documents.")

"""## âœï¸ Part 2: The Generator - Extracting the Answer

Now we set up our Generator. This model will take the question and the context found by the retriever and extract the exact answer from it.
"""

# Load our question-answering (generator) model
generator = pipeline('question-answering', model='distilbert-base-cased-distilled-squad')

print("âœ… Generator (QA) model loaded.")

"""## ğŸš€ Part 3: Testing our RAG System

Time to put it all together! The function below will simulate a full RAG pipeline and grade itself against a predefined set of questions and answers.

It will test two key things:
1.  **Retrieval Accuracy**: Did we find the right document?
2.  **Generation Accuracy**: Did we extract the correct answer from that document?
"""

def run_rag_assessment():
    """Runs a self-assessment of the RAG pipeline with multiple questions."""

    # Define our questions, expected context keywords, and expected answers
    test_questions = [
        {
            "question": "What is the highest mountain?",
            "expected_keyword": "Everest",
            "expected_answer": "Mount Everest"
        },
        {
            "question": "Which city is home to the Louvre museum?",
            "expected_keyword": "France",
            "expected_answer": "Paris"
        },
        {
            "question": "What process do plants use for energy?",
            "expected_keyword": "Photosynthesis",
            "expected_answer": "Photosynthesis"
        }
    ]

    score = 0
    total = len(test_questions) * 2 # 2 points per question (1 for retrieval, 1 for generation)

    print("--- ğŸš€ Starting RAG System Assessment ---\n")

    for i, test in enumerate(test_questions):
        question = test["question"]
        print(f"\n--- Question {i+1}: '{question}' ---")

        # --- 1. Retrieval Step ---
        question_embedding = retriever_model.encode(question, convert_to_tensor=True)
        cos_scores = util.pytorch_cos_sim(question_embedding, knowledge_embeddings)[0]
        top_result_index = torch.argmax(cos_scores)
        retrieved_context = knowledge_base[top_result_index]

        print(f"ğŸ”  Retrieved Context: '{retrieved_context}'")

        # Check if the retrieval was correct
        if test["expected_keyword"] in retrieved_context:
            print("âœ…  Retrieval Correct!")
            score += 1
        else:
            print(f"âŒ  Retrieval Failed. Expected context with keyword: '{test['expected_keyword']}'")

        # --- 2. Generation Step ---
        qa_result = generator(question=question, context=retrieved_context)
        generated_answer = qa_result['answer']

        print(f"âœï¸  Generated Answer: '{generated_answer}'")

        # Check if the generation was correct
        if test["expected_answer"].lower() in generated_answer.lower():
            print("âœ…  Generation Correct!")
            score += 1
        else:
            print(f"âŒ  Generation Failed. Expected answer: '{test['expected_answer']}'")

    # --- Final Score ---
    print(f"\n--- ğŸ Assessment Complete ---")
    print(f"ğŸ¯ Final Score: {score} / {total}")
    if score == total:
        print("ğŸ‰ğŸ‰ğŸ‰ Perfect! Your RAG system is working as expected!")
    elif score >= total / 2:
        print("ğŸ‘ Good job! The system is mostly correct.")
    else:
        print("ğŸ”§ The system ran into some issues. Review the steps and check the logic.")

# Run the assessment!
run_rag_assessment()

"""#  STUDENT TASKS ğŸ§‘â€ğŸ’»

Now it's your turn to be the AI engineer. Your tasks are to run, analyze, and extend the RAG system you've just built.

### Task 1: Execute and Understand

Your first task is to simply run all the cells above and carefully read the output of the final self-assessment.

* **Observe the Score:** Did the system get a perfect score (6/6)?
* **Analyze Each Step:** For each question, look at the "Retrieved Context" and the "Generated Answer."
    * Did the retriever find the correct piece of knowledge?
    * Did the generator extract the right answer from that context?

### Task 2 (Challenge): Add a New Question

Your second task is to test the system with a new question about the **existing knowledge**.

**Instructions:**
1.  Copy the code from the cell below. It's the same assessment function as before, but with a new test question added.
2.  Run the cell and see if the system can answer correctly. The score should now be out of 8.
"""

def run_rag_assessment_task_2():
    test_questions = [
        {
            "question": "What is the highest mountain?",
            "expected_keyword": "Everest",
            "expected_answer": "Mount Everest"
        },
        {
            "question": "Which city is home to the Louvre museum?",
            "expected_keyword": "France",
            "expected_answer": "Paris"
        },
        {
            "question": "What process do plants use for energy?",
            "expected_keyword": "Photosynthesis",
            "expected_answer": "Photosynthesis"
        },
        {
            "question": "What is the largest rainforest?",
            "expected_keyword": "Amazon",
            "expected_answer": "The Amazon rainforest"
        }
    ]

    score = 0
    total = len(test_questions) * 2

    print("--- ğŸš€ Starting RAG System Assessment (Task 2) ---\n")

    for i, test in enumerate(test_questions):
        question = test["question"]
        print(f"\n--- Question {i+1}: '{question}' ---")
        question_embedding = retriever_model.encode(question, convert_to_tensor=True)
        cos_scores = util.pytorch_cos_sim(question_embedding, knowledge_embeddings)[0]
        top_result_index = torch.argmax(cos_scores)
        retrieved_context = knowledge_base[top_result_index]
        print(f"ğŸ”  Retrieved Context: '{retrieved_context}'")
        if test["expected_keyword"] in retrieved_context:
            print("âœ…  Retrieval Correct!")
            score += 1
        else:
            print(f"âŒ  Retrieval Failed. Expected context with keyword: '{test['expected_keyword']}'")
        qa_result = generator(question=question, context=retrieved_context)
        generated_answer = qa_result['answer']
        print(f"âœï¸  Generated Answer: '{generated_answer}'")
        if test["expected_answer"].lower() in generated_answer.lower():
            print("âœ…  Generation Correct!")
            score += 1
        else:
            print(f"âŒ  Generation Failed. Expected answer: '{test['expected_answer']}'")

    print(f"\n--- ğŸ Assessment Complete ---")
    print(f"ğŸ¯ Final Score: {score} / {total}")
    if score == total:
        print("ğŸ‰ğŸ‰ğŸ‰ Perfect! Your RAG system handled the new question!")
    elif score >= total / 2:
        print("ğŸ‘ Good job! The system is mostly correct.")
    else:
        print("ğŸ”§ The system ran into some issues. Review the steps and check the logic.")

# Run the updated assessment
run_rag_assessment_task_2()

"""### Task 3 (Advanced Challenge): Add New Knowledge & Test It

Your final and most important task is to **expand the RAG system's knowledge base** and then test it.

**Instructions:**
1.  **Add a new fact** to the `knowledge_base` in the code cell below.
2.  **You must re-run this cell** to update the `knowledge_embeddings`! The system won't know about the new fact until you do.
3.  Finally, run the last code cell, which has a new test question about the knowledge you just added.
"""

# Task 3, Step 1: Add new sentences to the knowledge base

knowledge_base_task_3 = [
    "The State of Palestine is a UN observer state under Israeli occupation.",
    "The capital of Palestine is Jerusalem, with Ramallah serving as the administrative center.",
    "Gaza was the largest city in Palestine before 2023.",
    "The official language of Palestine is Arabic.",
    "In 2007, Palestinian Arabs constituted 91.2% of the ethnic groups in Palestine.",
    "Islam is the official religion in Palestine, accounting for 80.73% of the population in 2020.",
    "Christianity accounts for 0.88% of the religion in Palestine (2020).",
    "The demonym for Palestine is Palestinian.",
    "The government of Palestine is a unitary provisional semi-presidential republic.",
    "Mahmoud Abbas is the President of Palestine and Mohammad Mustafa is the Prime Minister.",
    "The Declaration of Independence for Palestine was proclaimed on 15 November 1988.",
    "The total area of Palestine is 6,020 km2, with the West Bank covering 5,655 km2 and the Gaza Strip 365 km2.",
    "The 2023 population estimate for Palestine is 5,483,450, with a density of 731/km2.",
    "The GDP (PPP) total for Palestine in 2023 was estimated at $36.391 billion, with a per capita of $6,642.",
    "The currencies used in Palestine include the Israeli new shekel, Jordanian dinar, and Egyptian pound.",
    "The national anthem of Palestine is 'FidÄÊ¾Ä«', which means 'Warrior'.",
    "Hussein al-Sheikh is the Vice President and Aziz Dweik is the Speaker of the Parliament of Palestine.",
    "The Legislative Council is the legislature of Palestine.",
    "The Human Development Index (HDI) for Palestine in 2023 was 0.674, categorised as medium.",
    "The climate in the West Bank is mostly Mediterranean, with cooler temperatures at elevated areas.",
    "The eastern West Bank includes much of the Judean Desert, which has a dry and hot climate.",
    "Gaza has a hot semi-arid climate with mild winters and dry hot summers.",
    "The hottest months in Palestine are July and August, with an average high of 33 Â°C (91 Â°F).",
    "The coldest month in Palestine is January, with temperatures usually at 7 Â°C (45 Â°F).",
    "Rain in Palestine is scarce and generally falls between November and March.",
    "Annual precipitation in Palestine is approximately 4.57 inches (116 mm).",
    "Palestine does not have officially recognized national parks or protected areas, but has nature reserves.",
    "Wadi Qelt, near Jericho in the West Bank, is a desert valley known for unique flora and fauna and historical sites.",
    "Efforts have been made to protect the biodiversity and natural beauty of Wadi Qelt.",
    "The Judaean Desert is known for its Judaean Camels.",
    "Qalqilya Zoo in Qalqilya Governorate is the only zoo currently active in Palestine."
]

# Re-encode the updated knowledge base
knowledge_embeddings_task_3 = retriever_model.encode(knowledge_base_task_3, convert_to_tensor=True)

print(f"âœ… Knowledge base updated and re-encoded with {len(knowledge_base_task_3)} documents.")

# Task 3, Step 2: Test your newly added knowledge

def run_rag_assessment_task_3():
    test_questions = [
        # --- NEW QUESTION FOR YOUR NEW KNOWLEDGE ---
        {
            "question": "What is the capital of Palestine?",
            "expected_keyword": "Jerusalem",
            "expected_answer": "Jerusalem"
        }
    ]

    score = 0
    total = len(test_questions) * 2

    print("--- ğŸš€ Starting RAG System Assessment (Task 3) ---\n")

    for i, test in enumerate(test_questions):
        question = test["question"]
        print(f"\n--- Question {i+1}: '{question}' ---")
        # Use the updated embeddings from Task 3
        question_embedding = retriever_model.encode(question, convert_to_tensor=True)
        cos_scores = util.pytorch_cos_sim(question_embedding, knowledge_embeddings_task_3)[0]
        # Use the updated knowledge base from Task 3
        top_result_index = torch.argmax(cos_scores)
        retrieved_context = knowledge_base_task_3[top_result_index]
        print(f"ğŸ”  Retrieved Context: '{retrieved_context}'")
        if test["expected_keyword"] in retrieved_context:
            print("âœ…  Retrieval Correct!")
            score += 1
        else:
            print(f"âŒ  Retrieval Failed. Expected context with keyword: '{test['expected_keyword']}'")
        qa_result = generator(question=question, context=retrieved_context)
        generated_answer = qa_result['answer']
        print(f"âœï¸  Generated Answer: '{generated_answer}'")
        if test["expected_answer"].lower() in generated_answer.lower():
            print("âœ…  Generation Correct!")
            score += 1
        else:
            print(f"âŒ  Generation Failed. Expected answer: '{test['expected_answer']}'")

    print(f"\n--- ğŸ Assessment Complete ---")
    print(f"ğŸ¯ Final Score: {score} / {total}")
    if score == total:
        print("ğŸ†ğŸ†ğŸ† Success! You have successfully extended the knowledge of your RAG system!")

# Run the final assessment
run_rag_assessment_task_3()